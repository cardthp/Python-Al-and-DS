[[package]]
name = "py4j"
version = "0.10.9"
description = "Enables Python programs to dynamically access arbitrary Java objects"
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "pyspark"
version = "3.1.2"
description = "Apache Spark Python API"
category = "main"
optional = false
python-versions = ">=3.6"

[package.dependencies]
py4j = "0.10.9"

[package.extras]
ml = ["numpy (>=1.7)"]
mllib = ["numpy (>=1.7)"]
sql = ["pandas (>=0.23.2)", "pyarrow (>=1.0.0)"]

[metadata]
lock-version = "1.1"
python-versions = "^3.9"
content-hash = "08797d97f6998ef029b7aee5578fc338a0799c7850b733e75cf570d6f6d75373"

[metadata.files]
py4j = [
    {file = "py4j-0.10.9-py2.py3-none-any.whl", hash = "sha256:859ba728a7bb43e9c2bf058832759fb97a598bb28cc12f34f5fc4abdec08ede6"},
    {file = "py4j-0.10.9.tar.gz", hash = "sha256:36ec57f43ff8ced260a18aa9a4e46c3500a730cac8860e259cbaa546c2b9db2f"},
]
pyspark = [
    {file = "pyspark-3.1.2.tar.gz", hash = "sha256:5e25ebb18756e9715f4d26848cc7e558035025da74b4fc325a0ebc05ff538e65"},
]
